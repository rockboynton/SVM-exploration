{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Vector Machines\n",
    "\n",
    "## Introduction\n",
    "\n",
    "## Summary of Results\n",
    "\n",
    "---\n",
    "\n",
    "## Setup \n",
    "\n",
    "First, we'll need to import the various libraries that we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn_pandas import CategoricalImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and Clean Data\n",
    "\n",
    "Before we can build any models, we need to import the data and clean it by converting types as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Adult/adult.data\", names=[\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"earning_label\"\n",
    "], skipinitialspace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore some attributes of the dataset\n",
    "\n",
    "# dir(df)\n",
    "print(\"Features: \", df.columns)\n",
    "print(\"Labels: \", pd.Series.unique(df.earning_label))\n",
    "print(\"Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# labels = combinations(df.columns, 2)\n",
    "# indices = combinations(range(len(df.columns)), 2)\n",
    "# for (x_label, y_label), (x1, x2) in zip(labels, indices):\n",
    "#     for i, target_name in enumerate(pd.Series.unique(df.earning_label)):\n",
    "#         income = df[ df.earning_label == i ]\n",
    "#         plt.scatter(income[:,x1], income[:,x2], label=target_name, alpha=0.7)\n",
    "#     plt.xlabel(x_label)\n",
    "#     plt.ylabel(y_label)\n",
    "#     plt.legend(loc='upper left')\n",
    "#     plt.show()\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "n = 100  # for 2 random indices\n",
    "index = np.random.choice(df.shape[0], n, replace=False) \n",
    "random = df.iloc[index, :]\n",
    "\n",
    "for i, target_name in enumerate(pd.Series.unique(df.earning_label)):\n",
    "        income = random[ random.earning_label == i ]\n",
    "        plt.scatter(random.capital_loss, random.capital_gain, label=target_name, alpha=0.7)\n",
    "plt.xlabel('fnlwgt')\n",
    "plt.ylabel(\"education_num\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the native.country variable has too many categories, and most of the data points are from the US (91%), we combine all the categories except for “United-States”into the “Other” category:\n",
    "df.loc[df['native_country']!='United-States', 'native_country']='Other'\n",
    "\n",
    "# Save the output label in binary encoding, 0: <=50k, 1: > 50k\n",
    "Y=pd.Categorical(df['earning_label']).codes\n",
    "Y = np.where(Y==0, -1, Y) \n",
    "print(Y)\n",
    "\n",
    "# Education is not needed as uducation_num performs its function\n",
    "# Also drop the label as it is not needed for the model\n",
    "df=df.drop(['education','earning_label'], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "col_names = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss','hours_per_week']\n",
    "features = df[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "df[col_names] = features\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine unique values of each categorical feature:\n",
    "col_names = ['workclass','marital_status','occupation','relationship','race','sex','native_country']\n",
    "for feature in col_names:\n",
    "    print(feature, pd.Series.unique(df[feature]))\n",
    "\n",
    "# impute missing values\n",
    "features = df[col_names]\n",
    "imp = SimpleImputer(strategy='most_frequent').fit(features.values)\n",
    "features = imp.transform(features.values)\n",
    "df[col_names] = features\n",
    "\n",
    "# Convert categorical features to one-hot encoding\n",
    "df=pd.get_dummies(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, split the data into training and testing sets 80\\/20\n",
    "partialData = df.values[:, [2, 5]]\n",
    "partialData = df.values\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(partialData, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greaterThan = np.where(train_Y == 1)\n",
    "print(greaterThan)\n",
    "gTCount = greaterThan[0].shape[0]\n",
    "print(gTCount)\n",
    "\n",
    "lT = np.where(train_Y == -1)[0]\n",
    "lT = np.random.permutation(lT)\n",
    "print(lT)\n",
    "print(lT.shape)\n",
    "\n",
    "index = np.hstack((lT[0:gTCount], greaterThan[0]))\n",
    "print(index.shape)\n",
    "train_Y = train_Y[index]\n",
    "print(train_Y)\n",
    "train_X = train_X[index]\n",
    "print(train_X)\n",
    "print(train_Y.shape)\n",
    "\n",
    "print(np.where(train_Y == -1)[0].shape[0])\n",
    "print(np.where(train_Y == 1)[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "for i in range(0, 6):\n",
    "    for j in range(i + 1, 6):\n",
    "        print((i, j))\n",
    "        print((df.columns[i], df.columns[j]))\n",
    "        plt.scatter(X[:, i], X[:, j], c=Y)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting the Model\n",
    "\n",
    "With the data now processed, it is ready to have SVM applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svm import SVM\n",
    "svm = SVM(10, .1)\n",
    "w = svm.fit(train_X, train_Y)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_Y = svm.predict(test_X, w)\n",
    "_X = np.hstack((test_X, np.ones((test_X.shape[0], 1))))\n",
    "p = np.sum(_X * w, axis=1)\n",
    "print(p)\n",
    "predicted_Y = p / abs(p)\n",
    "print(predicted_Y)\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print ((predicted_Y - test_Y == 0).sum() / test_Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = train_X\n",
    "y = train_Y\n",
    "print(y)\n",
    "\n",
    "independant_index = 2\n",
    "dependant_index = 3\n",
    "\n",
    "independant = X[:, independant_index]\n",
    "\n",
    "divBy = -w[dependant_index]\n",
    "multBy = w[independant_index]\n",
    "addBy = 0\n",
    "print (multBy)\n",
    "print(divBy)\n",
    "\n",
    "addBy += w[len(w) - 1]\n",
    "\n",
    "i1 = np.min(independant)\n",
    "i2 = np.max(independant)\n",
    "\n",
    "result = np.array([[i1, (i1 * multBy + addBy) / divBy],\n",
    "          [i2, (i2 * multBy + addBy) / divBy]])\n",
    "print(result)\n",
    "\n",
    "plt.plot(result[:, 0], result[:, 1], scaley=True)\n",
    "\n",
    "plt.scatter(X[:, independant_index], X[:, dependant_index], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='poly')\n",
    "clf.fit(train_X, train_Y)\n",
    "SVC()\n",
    "print(clf.predict(test_X))\n",
    "\n",
    "print(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_Y = clf.predict(test_X)\n",
    "print(predicted_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\")\n",
    "print ((predicted_Y - test_Y == 0).sum() / test_Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\")\n",
    "print ((predicted_Y - test_Y == 0).sum() / test_Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acknowlegements\n",
    "\n",
    "https://methods.sagepub.com/dataset/howtoguide/support-vector-machine-in-aci-1996-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.1 64-bit ('root': conda)",
   "language": "python",
   "name": "python36164bitrootconda6e0c314544c443b5938248d6fa4e1245"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
