{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda32b04c9e2a3b40a4a549c2ff9baea20b",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Vector Machines\n",
    "\n",
    "## Introduction\n",
    "\n",
    "## Summary of Results\n",
    "\n",
    "---\n",
    "\n",
    "## Setup \n",
    "\n",
    "First, we'll need to import the various libraries that we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and Clean Data\n",
    "\n",
    "Before we can build any models, we need to import the data and clean it by converting types as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Adult/adult.data\", names=[\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"earning_label\"\n",
    "], skipinitialspace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore some attributes of the dataset\n",
    "\n",
    "# dir(df)\n",
    "print(\"Features: \", df.columns)\n",
    "print(\"Labels: \", pd.Series.unique(df.earning_label))\n",
    "print(\"Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the native.country variable has too many categories, and most of the data points are from the US (91%), we combine all the categories except for “United-States”into the “Other” category:\n",
    "df.loc[df['native_country']!='United-States', 'native_country']='Other'\n",
    "\n",
    "# Save the output label in binary encoding, 0: <=50k, 1: > 50k\n",
    "Y=pd.Categorical(df['earning_label']).codes\n",
    "Y = np.where(Y==0, -1, Y) \n",
    "print(Y)\n",
    "\n",
    "# education is not needed as uducation_num performs its function\n",
    "# also drop the label as it is not needed for the model\n",
    "df=df.drop(['education','earning_label'], axis=1)\n",
    "\n",
    "# determine unique values of each categorical feature:\n",
    "for feature in ['workclass','marital_status','occupation','relationship','race','sex','native_country']:\n",
    "    print(feature, pd.Series.unique(df[feature]))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features to one-hot encoding\n",
    "df=pd.get_dummies(df)\n",
    "df\n",
    "\n",
    "# encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "# encoder.fit(df)\n",
    "# df = encoder.transform(df)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, split the data into training and testing sets 80\\/20\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(df.values, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting the Model\n",
    "\n",
    "With the data now processed, it is ready to have SVM applied"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acknowlegements\n",
    "\n",
    "https://methods.sagepub.com/dataset/howtoguide/support-vector-machine-in-aci-1996-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}